{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b687eebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5846db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep learning inspired by how the human brain learns \n",
    "#Neural networks are a set of algorithms, modeled loosely after the human brain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a70f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch Sensor # Similar to array or matrix \n",
    "#Tensors are the building blocks of deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d03df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "my_list = [[1,2,3],[4,5,6]]\n",
    "my_tensor = torch.tensor(my_list)\n",
    "print(my_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8757ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.int64\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "my_list = [[1,2,3],[4,5,6]]\n",
    "my_tensor = torch.tensor(my_list)\n",
    "print(my_tensor.shape)\n",
    "print(my_tensor.dtype)\n",
    "print(my_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c65301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2],\n",
      "        [6, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "a = torch.tensor([[1,1], [2,2]])\n",
    "b = torch.tensor([[2,2], [3,3]])\n",
    "result = a * b \n",
    "print(result)\n",
    "# row * column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74762b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Neural network consisto of input output and hidden layers \\n    Input layer : dataset features \\n    Ouput layer : predictions \\n    Hidden layers : They lie between input and output layers and consist of various hidden layers \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First neural network in pytorch tensors \n",
    "''' Neural network consisto of input output and hidden layers \n",
    "    Input layer : dataset features \n",
    "    Ouput layer : predictions \n",
    "    Hidden layers : They lie between input and output layers and consist of various hidden layers \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10673e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing as nn to avovid writing as torch.nn and \n",
    "# Input neurons : features in our dataset \n",
    "# Output : number of classes we watn to rpredit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b4faa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1981, 0.3240]], grad_fn=<AddmmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.0747, -0.0305,  0.3228],\n",
      "        [-0.2709,  0.2250, -0.4945]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3139, 0.1992], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Creating input_tensor with three features\n",
    "input_tensor = torch.tensor([[0.3471, 0.4547, -0.2356]])  # Note the double square brackets\n",
    "\n",
    "# Defining the linear layer as it applies a linear transformation to the incoming data\n",
    "linear_layer = nn.Linear(\n",
    "    in_features=3,\n",
    "    out_features=2\n",
    ")\n",
    "\n",
    "# Passing the input through the linear layer\n",
    "output = linear_layer(input_tensor)\n",
    "print(output)\n",
    "print(linear_layer.weight)\n",
    "print(linear_layer.bias)\n",
    "\n",
    "# Weight reflects the importance of different features \n",
    "# bias provides neuron iwth a baseline output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc4b612f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Example for linear prediction using weight and bias \\nSuppose we are having the 3 inputs having temrpeature humidity and wind and the output of 2 then the \\nhumidity will have the more significant weight to predict whether it will be cloudy or sunny \\n\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Example for linear prediction using weight and bias \n",
    "Suppose we are having the 3 inputs having temrpeature humidity and wind and the output of 2 then the \n",
    "humidity will have the more significant weight to predict whether it will be cloudy or sunny \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49683016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=8, bias=True)\n",
      "  (1): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (2): Linear(in_features=4, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the number of input features\n",
    "n_features = 10  # Replace with the actual number of features in your data\n",
    "\n",
    "# Define the number of output classes\n",
    "n_classes = 3   # Replace with the actual number of classes in your task\n",
    "\n",
    "# Creating the network with three linear layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 8),\n",
    "    nn.Linear(8, 4),\n",
    "    nn.Linear(4, n_classes)\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1eed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(8,4), nn.Linear(4,2))\n",
    "# First layer has 4 neurons and each neuron has 8+ 1 9 parameters and 9 *4 = 36 parameters \n",
    "total = 0 \n",
    "for parameter in model.parameters():\n",
    "    total  = total + parameter.numel()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96603465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Activity functions added non-linearty to the network \\n    Sigmode for binary classification \\n    Softmax for multi class classification \\n    Suppose we are trying to know whether we have mamal or not we have 3 input layers limbs eggs hair and then \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Activity functions added non-linearty to the network \n",
    "    Sigmode for binary classification \n",
    "    Softmax for multi class classification \n",
    "    Suppose we are trying to know whether we have mamal or not we have 3 input layers limbs eggs hair and then \n",
    "    4 linear layers there \n",
    "     ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c60f8b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9975]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sigmoid is an activation function used in binary classification (e.g., yes/no predictions).\\n\\nIt converts logits (raw model outputs) into probabilities.\\n\\nOutput range: (0, 1) (useful for probabilities).\\n\\nExample use case: Final layer in a binary classifier (e.g., spam detection).'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "input_tensor = torch.tensor([[6]])\n",
    "sigmoid = nn.Sigmoid()\n",
    "output = sigmoid(input_tensor)\n",
    "print(output)\n",
    "\n",
    "'''Sigmoid is an activation function used in binary classification (e.g., yes/no predictions).\n",
    "\n",
    "It converts logits (raw model outputs) into probabilities.\n",
    "\n",
    "Output range: (0, 1) (useful for probabilities).\n",
    "\n",
    "Example use case: Final layer in a binary classifier (e.g., spam detection).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36bff007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n 1.0 |        *\\n     |       *\\n     |      *\\n     |     *\\n0.5 |----*---------\\n     |   *\\n     |  *\\n     | *\\n0.0 +----------------\\n      -6  0  6            '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    " 1.0 |        *\n",
    "     |       *\n",
    "     |      *\n",
    "     |     *\n",
    "0.5 |----*---------\n",
    "     |   *\n",
    "     |  *\n",
    "     | *\n",
    "0.0 +----------------\n",
    "      -6  0  6            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "510671fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1392, 0.8420, 0.0188]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "# 1. Create a 1x3 tensor (3 raw scores/logits for 3 classes)\n",
    "input_tensor = torch.tensor([[4.3, 6.1, 2.3]])\n",
    "\n",
    "# 2. Initialize Softmax (dim=-1 applies it to the last dimension)\n",
    "probabilities = nn.Softmax(dim=-1)\n",
    "\n",
    "# 3. Apply Softmax to convert logits to probabilities\n",
    "output_tensor = probabilities(input_tensor)\n",
    "\n",
    "# 4. Print the result\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71740a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nConcept\\tKey Takeaway\\nSoftmax\\tConverts logits to probabilities for multi-class problems. Sums to 1.\\nSigmoid\\tUsed for binary classification. Outputs independent probabilities (0 to 1).\\nUse Case\\tUse Softmax for >2 classes, Sigmoid for 2 classes.\\nPyTorch\\tnn.Softmax(dim=1) for probabilities, CrossEntropyLoss for training\\n '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Concept\tKey Takeaway\n",
    "Softmax\tConverts logits to probabilities for multi-class problems. Sums to 1.\n",
    "Sigmoid\tUsed for binary classification. Outputs independent probabilities (0 to 1).\n",
    "Use Case\tUse Softmax for >2 classes, Sigmoid for 2 classes.\n",
    "PyTorch\tnn.Softmax(dim=1) for probabilities, CrossEntropyLoss for training\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29653926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5701],\n",
      "        [0.5795],\n",
      "        [0.5344],\n",
      "        [0.5959],\n",
      "        [0.5879]], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\nHere, input dimension = 6 (6 features of each animal), output dimension = 4 (4 neurons).\\nThis reduces/expands the feature information — from 6 features into 4 new learned features\\nnn.Linear(4, 1)\\nNow the output of first layer (size 4) is passed into another linear layer.\\nInput = 4, Output = 1.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward passs : input data flows through layers calculations performed at each other \n",
    "# Output is based on weights and biases \n",
    "# Used for traning and prediction \n",
    "# Possible classifications : binary classifications , multi-class classification \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "input_tensor = torch.tensor([[0.1234, 0.5678, 0.9012, 0.3456, 0.7890, 0.2345],\n",
    "        [0.9876, 0.4321, 0.1098, 0.6789, 0.3210, 0.8765],\n",
    "        [0.5432, 0.8765, 0.2109, 0.9012, 0.4567, 0.1234],\n",
    "        [0.7654, 0.2198, 0.5432, 0.1098, 0.8901, 0.3456],\n",
    "        [0.3210, 0.6543, 0.9876, 0.2345, 0.5678, 0.8901]])\n",
    "\n",
    "# Suppose we have 5 * 6 shape where there are 5 animals and six features \n",
    "# Creating the model using sigmoid function which is used for binary classification \n",
    "\n",
    "model = nn.Sequential(\n",
    "nn.Linear(6 ,4),\n",
    "nn.Linear(4,1),\n",
    "nn.Sigmoid() # sigmoid activation function \n",
    "\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)\n",
    "\n",
    "''' \n",
    "Here, input dimension = 6 (6 features of each animal), output dimension = 4 (4 neurons).\n",
    "This reduces/expands the feature information — from 6 features into 4 new learned features\n",
    "nn.Linear(4, 1)\n",
    "Now the output of first layer (size 4) is passed into another linear layer.\n",
    "Input = 4, Output = 1.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93e78b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWhy Linear layers?:\\n\\nThey learn the relationships between features and outputs.\\n\\nNo non-linearity until activation function is added.\\n\\nWhy Sigmoid?:\\n\\nFor binary classification to predict a probability between 0 and 1.\\n\\nOtherwise (for multiclass classification), you'd use something else like Softmax. \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Why Linear layers?\n",
    "\n",
    "They learn the relationships between features and outputs.\n",
    "No non-linearity until activation function is added.\n",
    "\n",
    "Why Sigmoid?\n",
    "For binary classification to predict a probability between 0 and 1.\n",
    "Otherwise (for multiclass classification), you'd use something else like Softmax. '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d2abc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "tensor([[0.1915, 0.3374, 0.4711],\n",
      "        [0.1678, 0.2989, 0.5333],\n",
      "        [0.1790, 0.3133, 0.5077],\n",
      "        [0.1812, 0.3154, 0.5034],\n",
      "        [0.1718, 0.3356, 0.4927]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "''' \n",
    "class 1 - mammal \n",
    "class 2 - bird \n",
    "class 3 - reptile \n",
    "'''\n",
    "\n",
    "n_classes = 3\n",
    "\n",
    "# Creating the multiclass classification model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6, 4),    # First Linear layer: input 6 features -> output 4 features\n",
    "    nn.Linear(4, n_classes),  # Second Linear layer: 4 features -> 3 class scores\n",
    "    nn.Softmax(dim=-1)  # Softmax activation across the classes\n",
    ")\n",
    "\n",
    "\n",
    "'''1. nn.Linear(6, 4)\n",
    "Input: 6 features (example: weight, size, temperature, etc.)\n",
    "\n",
    "Output: 4 neurons (abstract features learned by the network).\n",
    "\n",
    "Purpose:\n",
    "\n",
    "Transform the raw input into new feature representations.\n",
    "\n",
    "2. nn.Linear(4, n_classes)\n",
    "(where n_classes = 3)\n",
    "\n",
    "Input: 4 features (from the previous layer).\n",
    "\n",
    "Output: 3 numbers (one for each class: mammal, bird, reptile).\n",
    "\n",
    "Purpose:\n",
    "\n",
    "Produce raw scores (called logits) for each class.'''\n",
    "\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output.shape)\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff39b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6023]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Regression model regression → the output should be a continuous real number, not probabilities.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 11 input features\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a neural network with exactly four linear layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(11, 64),   # Layer 1: 11 → 64\n",
    "    nn.Linear(64, 32),   # Layer 2: 64 → 32\n",
    "    nn.Linear(32, 16),   # Layer 3: 32 → 16\n",
    "    nn.Linear(16, 1)     # Layer 4: 16 → 1 (regression output)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61a776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
